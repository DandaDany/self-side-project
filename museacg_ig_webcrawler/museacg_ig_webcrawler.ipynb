{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18c8589a-e7ca-40aa-b3d7-94a3cb1f799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import undetected_chromedriver as uc\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee91e857-dc48-4561-86fb-d2c1d7433571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_browser():\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "    options.add_argument('--disable-infobars')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.6834.160 Safari/537.36')\n",
    "    \n",
    "    browser = uc.Chrome(\n",
    "        options=options,\n",
    "        version_main=132\n",
    "    )\n",
    "    return browser\n",
    "\n",
    "def collect_links(browser, target_count=10000):\n",
    "    link = []\n",
    "    while True:\n",
    "        try:\n",
    "            page_source = browser.execute_script(\"return document.documentElement.outerHTML\")\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "            \n",
    "            for soup1 in soup.find_all('div', class_='x1lliihq x1n2onr6 xh8yej3 x4gyw5p x1ntc13c x9i3mqj x11i5rnm x2pgyrj'):\n",
    "                superlink = soup1.find('a', class_='x1i10hfl xjbqb8w x1ejq31n xd10rxx x1sy0etr x17r0tee x972fbf xcfux6l x1qhh985 xm0m39n x9f619 x1ypdohk xt0psk2 xe8uvvx xdj266r x11i5rnm xat24cr x1mh8g0r xexx8yu x4uap5 x18d9i69 xkhd6sd x16tdsg8 x1hl2dhg xggy1nq x1a2a7pz _a6hd')\n",
    "                \n",
    "                if superlink:\n",
    "                    href_link = superlink.get('href')\n",
    "                    if 'muse' in href_link and 'followers' not in href_link:\n",
    "                        linkss = 'https://www.instagram.com' + href_link\n",
    "                        if linkss not in link:\n",
    "                            link.append(linkss)\n",
    "                            print(f\"找到的連結 ({len(link)}): {linkss}\")\n",
    "            \n",
    "            # 滾動頁面\n",
    "            browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(2)  # 增加等待時間以確保內容加載\n",
    "            \n",
    "            if len(link) >= target_count:\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"收集連結時發生錯誤: {str(e)}\")\n",
    "            break\n",
    "            \n",
    "    return link\n",
    "\n",
    "def analyze_posts(browser, links, keywords):\n",
    "    filtered_posts = []\n",
    "    posts = []\n",
    "    keywords = ['泰國','越南','印尼']\n",
    "\n",
    "    for index, link in enumerate(links, 1):\n",
    "        try:\n",
    "            print(f\"處理第 {index}/{len(links)} 個連結\")\n",
    "            browser.get(link)\n",
    "            time.sleep(5)\n",
    "            \n",
    "            page_source = browser.execute_script(\"return document.documentElement.outerHTML\")\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "            \n",
    "            for context in soup.find_all('h1', class_='_ap3a *aaco *aacu *aacx *aad7 _aade'):\n",
    "                post_text = context.text\n",
    "                posts.append(post_text)\n",
    "                \n",
    "                if any(keyword in post_text for keyword in keywords):\n",
    "                    filtered_posts.append(post_text)\n",
    "                    print(f\"找到符合關鍵字的貼文: {post_text}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"分析貼文時發生錯誤: {str(e)}\")\n",
    "            continue\n",
    "            \n",
    "    return posts, filtered_posts\n",
    "\n",
    "def main():\n",
    "    browser = None\n",
    "    try:\n",
    "        browser = setup_browser()\n",
    "        print(\"瀏覽器創建成功\")\n",
    "        \n",
    "        # 訪問Instagram\n",
    "        browser.get('https://www.instagram.com/museacg/')\n",
    "        print(\"頁面訪問成功\")\n",
    "        \n",
    "        # 登入流程\n",
    "        time.sleep(5)\n",
    "        login_element = WebDriverWait(browser, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//div[contains(text(), '登入')]\"))\n",
    "        )\n",
    "        login_element.click()\n",
    "        print(\"點擊登入按鈕\")\n",
    "        \n",
    "        WebDriverWait(browser, 10).until(\n",
    "            EC.presence_of_element_located((By.NAME, \"username\"))\n",
    "        )\n",
    "        \n",
    "        username = browser.find_element(By.NAME, 'username')\n",
    "        password = browser.find_element(By.NAME, \"password\")\n",
    "        \n",
    "        username.send_keys(\"在此輸入個人帳號\")\n",
    "        password.send_keys(\"在此輸入個人密碼\")\n",
    "        print(\"輸入帳號密碼\")\n",
    "        \n",
    "        browser.find_element(By.XPATH, '//button[@type=\"submit\"]').click()\n",
    "        print(\"點擊登入按鈕\")\n",
    "        \n",
    "        time.sleep(5)\n",
    "        \n",
    "        # 重新訪問目標頁面\n",
    "        browser.get('https://www.instagram.com/museacg/')\n",
    "        print(\"重新訪問頁面成功\")\n",
    "        \n",
    "        time.sleep(5)\n",
    "        \n",
    "        # 收集連結\n",
    "        print(\"開始收集連結...\")\n",
    "        links = collect_links(browser)\n",
    "        print(f\"總共收集到 {len(links)} 個連結\")\n",
    "        \n",
    "        # 分析貼文\n",
    "        print(\"開始分析貼文...\")\n",
    "        keywords = ['泰國', '越南', '印尼']\n",
    "        posts, filtered_posts = analyze_posts(browser, links, keywords)\n",
    "        \n",
    "        print(f\"分析完成！總共找到 {len(filtered_posts)} 個符合關鍵字的貼文\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"發生錯誤: {str(e)}\")\n",
    "    \n",
    "    finally:\n",
    "        if browser:\n",
    "            browser.quit()\n",
    "            print(\"瀏覽器已關閉\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cffa3e9-da4a-4578-8614-91d1345171e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
